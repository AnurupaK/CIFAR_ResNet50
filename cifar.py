# -*- coding: utf-8 -*-
"""CIFAR.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tx64RjiR-8fxdVkrybb5FURCIjPP9ivZ
"""

!pip install kaggle

!pip install py7zr

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle competitions download -c cifar-10

from zipfile import ZipFile

dataset = '/content/cifar-10.zip'
with ZipFile(dataset, 'r') as zip:
    zip.extractall()
    print('The main dataset is extracted')

import pandas as pd
import numpy as np
import cv2
import os
from google.colab.patches import cv2_imshow
from PIL import Image
from sklearn.model_selection import train_test_split
import matplotlib.image as mpimg
import matplotlib.pyplot as plt
import py7zr

train_path = '/content/train.7z'

archive = py7zr.SevenZipFile('/content/train.7z', mode='r')
archive.extractall()
archive.close

train_images_path = '/content/train/'
train_images = os.listdir(train_images_path)
print(len(train_images))


for i in range(10):
    file = train_images[i]
    img = cv2.imread(train_images_path + file)
    # cv2_imshow(img)

print(train_images[0:5])

df = pd.read_csv('/content/trainLabels.csv')

df.head(5)

print(train_images)

# train_new_images = []

# for ID in list(df['id']):
#     for img in train_images:
#        img_new = img[:-4]
#        img_new = int(img_new)
#        if ID==img_new:
#           train_new_images.append(img)

# print(train_new_images)

for i in range(10):
   id = list(df['id'])[i]
   name = str(id) +'.png'
   name = str(name)
   if name in train_images:
         print(name)

"""Check for jpg and png extension"""

import glob
import os


train_images_path = '/content/train/'
extension =['jpg','png']
for ext in extension:
  if ext=='jpg':
    pattern = os.path.join(train_images_path, f'*.{ext}')
    jpg_files = glob.glob(pattern)
    print(f"Number of .jpg files found: {len(jpg_files)}")
  else:
    pattern = os.path.join(train_images_path, f'*.{ext}')
    jpg_files = glob.glob(pattern)
    print(f"Number of .png files found: {len(jpg_files)}")

##Using Numpy
id_array = np.asarray(df['id'])
new_id_array = np.char.add(id_array.astype(str), '.png')

print(new_id_array)

##Using Pandas
df['Image_files'] = df['id'].astype(str) + '.png'

df.head(5)

df = df[['id','Image_files','label']]
cifar_df = df.copy()

import os
import cv2

def check_image_dimensions(directory, extensions=['jpg', 'png' ,'jpeg']):
    # Get the list of all image files in the directory
    image_files = []
    for ext in extensions:
        image_files.extend(glob.glob(os.path.join(directory, f'*.{ext}')))

    if not image_files:
        print("No images found in the specified directory.")
        return

    # Read the first image to get the reference dimensions
    j = 0
    first_image = None
    while j < len(image_files):
        first_image = cv2.imread(image_files[j])
        if first_image is not None:
            point = j
            break
        j += 1

    if first_image is None:
        print("No valid images found in the specified directory.")
        return



    ref_height, ref_width, _ = first_image.shape
    print(f"Reference dimensions: {ref_width}x{ref_height}")

    # Check dimensions of all other images
    for i, file_path in enumerate(image_files[point:]):
        image = cv2.imread(file_path)
        if image is None:
            print(f"Failed to read the image: {file_path}")
            continue

        height, width, _ = image.shape
        if (height, width) != (ref_height, ref_width):
            print(f"Image {file_path} has different dimensions: {width}x{height}")
            return False

        if i % 1000 == 0:  # Print progress every 1000 images
            print(f"Checked {i} images...")

    print("All images have the same dimensions.")
    return True

train_images_path = '/content/train/'
check_image_dimensions(train_images_path)

train_images_path = '/content/train/'

image_list = []
for i in range(5):
   img_file = df['Image_files'][i]
   if img_file in train_images:
      img = cv2.imread(train_images_path + img_file)
      img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
      image_list.append(img)

image_list = np.asarray(image_list)
print(image_list.shape)

all_labels = cifar_df['label'].unique()
all_labels = sorted(all_labels)

print(all_labels)

label_dict = {}
for i,label in enumerate(all_labels):
    label_dict[label] = i

print(label_dict)

"""Label Encoding"""

label_list = []
for i in cifar_df['label']:
    label_list.append(label_dict[i])

print(label_list)

cifar_df['Encodings'] = label_list

cifar_df.head(10)

train_path = '/content/train/'

for i in range(5):
   file = list(cifar_df['Image_files'])[i]
   img = cv2.imread(train_path + file)
   cv2_imshow(img)

###For all 50000 data
train_images_path = '/content/train/'

image_list = []
for i in range(50000):
   if i/1000==0:
      print(f'{i} image processed')
   img_file = df['Image_files'][i]
   if img_file in train_images:
      img = cv2.imread(train_images_path + img_file)
      img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
      image_list.append(img)

image_list = np.asarray(image_list)
print(image_list.shape)

X = image_list
Y = np.asarray(cifar_df['Encodings'])

X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.3,stratify=Y, random_state=2)

X_train_scale = X_train/255
X_test_scale = X_test/255

"""Building Neural Network"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense,Activation,Flatten

output_classes = 10

model = Sequential([

                    Flatten(input_shape=(32,32,3)),
                    Dense(64, activation='relu'),
                    Dense(output_classes, activation ='softmax')

])

model.summary()

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

history = model.fit(X_train_scale,Y_train, epochs=10, validation_split=0.1)

"""From here we observed that the accuarcy for our model is not good and is consistent till 40%. It is because we don't have Convulational layers and thats why we use pre trained neural networks. Here we will use ResNet 50"""

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend(['Training data','Validation data'],loc='lower right')

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend(['Training data','Validation data'],loc='lower right')

"""Wrapping our model with resnet50"""

from tensorflow.keras import Sequential, models, layers
from tensorflow.keras.layers import Dense,Flatten,Dropout, BatchNormalization
from tensorflow.keras.models import load_model
from tensorflow.keras.models import Model
from tensorflow.keras.applications.resnet50 import ResNet50
from tensorflow.keras import optimizers

"""imagenet is the image dataset on which ResNet is trained.
So when we are using parameter weights, it is capturing all the weights it received during its training with imagenet dataset.
include_top=False means to delete the last output layer of resnet as we just have 10classes to predict and imagenet dataset has millions classes to predict.
Finally the resnet neural network takes in (256,256,3) shape image. This we need to remember.
"""

convolutional_base = ResNet50(weights='imagenet',include_top=False, input_shape=(256,256,3))
convolutional_base.summary()

model = models.Sequential()
model.add(layers.UpSampling2D((2,2)))
model.add(layers.UpSampling2D((2,2)))
model.add(layers.UpSampling2D((2,2)))
model.add(convolutional_base)
model.add(Flatten())
model.add(BatchNormalization())
model.add(Dense(128,activation='relu'))
model.add(Dropout(0.5))
model.add(BatchNormalization())
model.add(Dense(64,activation='relu'))
model.add(Dropout(0.5))
model.add(BatchNormalization())
model.add(Dense(output_classes, activation='relu'))

"""In the above code, lets understand the layers,

First the UpSampling2D((2,2)) * 3times..why??

well our image dimension is 32 x 32 and resnet takes in 256 x 256, so width = 32x2x2x2 = 256 and height 32x2x2x2 = 256

basically to upsacle our current input images to the images pre trained model will take in. Amazing right!!! :)

Then we are passing all these upsacled images to our convolutional base.

Doing Flatten to make it in 1D as NN takes ID as input

Then doing BatchNormalization which is just to scale all the input image array. Well in our case we have already scaled our images but stricly speaking if we have scaled the images beforehand then we don't need to add the BatchNormalisation. Adding will just make the model more efficient, thats it.

Well the flatten layer is our input layer. Right. But from where it is taking input from?
It is taking input from the convulational base and passing it to hidden layers. So it may happen the input layer is passing values to hidden layers which are not scaled and hence adding a BatchNormalization will keep you in safer side.

Dropout is to ensure the model is not getting overfit. So it will turn off few neurons with the value mentioned in dropout.
"""

model.compile(optimizer=optimizers.RMSprop(learning_rate=2e-5),
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

history = model.fit(X_train_scale,Y_train, epochs=10, validation_split=0.1)

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend(['Training data','Validation data'],loc='lower right')

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend(['Training data','Validation data'],loc='lower right')

"""Model Evaluation"""

loss, accuracy = model.evaluate(X_test_scale,Y_test)
print(f'Loss: {loss} | Accuracy: {accuracy}')

from keras.models import load_model

loaded_model = load_model('CustomizeResNet50.h5')